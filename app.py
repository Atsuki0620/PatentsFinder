import os
import json
import yaml
import streamlit as st
from google.oauth2 import service_account
from src.utils.patent_utils import PatentSearchUtils

# --- è¨­å®šãƒ­ãƒ¼ãƒ‰ ---
@st.cache_resource
def load_config():
    with open("config/config.yaml", "r", encoding="utf-8") as f:
        return yaml.safe_load(f)

cfg = load_config()
proposal_system_prompt = cfg['chat_flow']['proposal_prompt']

# ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ãªåˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
initial_prompt = cfg['chat_flow'].get(
    'initial_prompt',
    "ã“ã‚“ã«ã¡ã¯ï¼ğŸš€ ã©ã‚“ãªç‰¹è¨±æƒ…å ±ã‚’ãŠæ¢ã—ã§ã™ã‹ï¼Ÿæ°—ã«ãªã‚‹æŠ€è¡“ã‚„å…¬é–‹æ—¥ã€èª¿æŸ»ã—ãŸã„å›½ã‚„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãªã©ã€æ€ã„ã¤ãã¾ã¾æ•™ãˆã¦ãã ã•ã„â™ª"
)

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ– ---
if 'mode' not in st.session_state:
    st.session_state.mode = 'question'      # question, proposal, execute
    st.session_state.chat_history = []      # ä¼šè©±å±¥æ­´
    st.session_state.proposal = None        # ææ¡ˆå†…å®¹

# --- Secrets è¨­å®š ---
sa_info = st.secrets.get("GCP_SERVICE_ACCOUNT") or os.getenv("GCP_SERVICE_ACCOUNT")
credentials = service_account.Credentials.from_service_account_info(json.loads(sa_info))
openai_key = st.secrets.get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")

@st.cache_resource
def get_utils():
    return PatentSearchUtils(
        config=cfg,
        credentials=credentials,
        openai_api_key=openai_key
    )

# --- ãƒãƒ£ãƒƒãƒˆUIç”¨é–¢æ•° ---
def render_chat():
    for msg in st.session_state.chat_history:
        role = msg['role'] if msg['role'] != 'system' else 'assistant'
        st.chat_message(role).write(msg['content'])

# --- ãƒ•ã‚§ãƒ¼ã‚ºã”ã¨ã® UI ---
def question_phase():
    # åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¡¨ç¤º
    if not any(m['role']=='system' and m['content']==initial_prompt for m in st.session_state.chat_history):
        st.session_state.chat_history.append({'role':'system','content': initial_prompt})
    render_chat()
    user_input = st.chat_input("è‡ªç”±ã«å…¥åŠ›ã—ã¦ãã ã•ã„â€¦")
    if user_input:
        st.session_state.chat_history.append({'role':'user', 'content': user_input})
        st.session_state.mode = 'proposal'
        st.experimental_rerun()


def proposal_phase():
    render_chat()
    # LLMã«ã‚ˆã‚‹ææ¡ˆç”Ÿæˆ
    utils = get_utils()
    messages = [
        {'role': 'system', 'content': proposal_system_prompt},
        {'role': 'user', 'content': st.session_state.chat_history[-1]['content']}
    ]
    resp = utils.openai_client.chat.completions.create(
        model=utils.llm_model,
        messages=messages,
        temperature=0
    )
    proposal = resp.choices[0].message.content.strip()
    st.session_state.proposal = proposal
    st.session_state.chat_history.append({'role':'assistant','content': proposal})
    render_chat()
    st.code(proposal, language='json')
    # é¸æŠè‚¢è¡¨ç¤º
    if st.button("ğŸ” ã“ã®æ–¹é‡ã§æ¤œç´¢å®Ÿè¡Œ"):
        st.session_state.mode = 'execute'
        st.experimental_rerun()
    if st.button("âœï¸ æ–¹é‡ã‚’ä¿®æ­£ã™ã‚‹"):
        st.session_state.mode = 'question'
        st.session_state.chat_history = []
        st.experimental_rerun()


def execute_phase():
    render_chat()
    utils = get_utils()
    try:
        params = json.loads(st.session_state.proposal)
    except json.JSONDecodeError:
        st.chat_message("assistant").write(
            "ã‚ã‚Œï¼Ÿææ¡ˆã•ã‚ŒãŸå†…å®¹ãŒJSONã¨ã—ã¦èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦æ•™ãˆã¦ã‚‚ã‚‰ãˆã‚‹ã¨åŠ©ã‹ã‚Šã¾ã™ï¼"
        )
        if st.button("å†å…¥åŠ›ã™ã‚‹"):
            st.session_state.mode = 'question'
            st.session_state.chat_history = []
            st.experimental_rerun()
        return

    df = utils.search_patents(utils.build_query(params))
    st.chat_message("assistant").write(f"çµæœãŒå‡ºã¾ã—ãŸï¼{len(df)} ä»¶ã®ç‰¹è¨±ã‚’è¦‹ã¤ã‘ã¾ã—ãŸğŸ™‚")
    st.dataframe(df)
    csv_data = df.to_csv(index=False).encode('utf-8-sig')
    st.download_button("CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", csv_data, "results.csv", "text/csv")

# --- ãƒ¡ã‚¤ãƒ³ ---
st.title("ğŸ” ç‰¹è¨±èª¿æŸ»æ”¯æ´ã‚·ã‚¹ãƒ†ãƒ ï¼ˆãƒãƒ£ãƒƒãƒˆUIç‰ˆï¼‰")
if st.session_state.mode == 'question':
    question_phase()
elif st.session_state.mode == 'proposal':
    proposal_phase()
else:
    execute_phase()
